# DOTS - 面向数据的技术栈

Data-Oriented Technology Stack

Unity 通过 5个核心包定义 + 额外包 的全新的Unity代码编写模型



# 5个核心包



## Job System 

​	多线程代码 更容易利用现代CPU多核处理并行任务



## Burst

​	优化C#代码的编译器，比 Mono、IL2CPP 更快，不止可以编译DOTS代码，也可以编译Unity中的任何代码



## Mathematics

​	可以在 Job System 中使用的数学库，在Burst编译后的代码有经过特别优化



## Collections

​	列表、Hash映射

​	常见集合类 的内存分配 属于非 C# 的托管类型，可以在 Burst 编译代码中的 Job System 中使用，并且这些类型支持安全检查（能在 Job System 中安全使用）



## Entities（ECS）

​	Entity 对象比 GameObject 更轻量 更高效的替代品，本身不承担任何代码，

​	Component 只是数据片段集合

​	E、C 都由对应的 System 代码单元进行处理



# 扩展包

## Entities.Graphics

​	即 DOTS 1.0 之前的 Hybrid Renderer

​	支持 URP 与 HDRP 的 Entities 的渲染解决方案

​	注意：这个包 不优化 GPU 的性能，而是优化 CPU 上的 性能



## NetCode

​	建立五个核心包基础上的 - DOTS 网络解决方案

​	网络多人连线的服务器功能，与客户端预测等功能



## Physics

​	建立五个核心包基础上的 - 物理解决方案

​	支持2个后端：

​	1、默认 Unity Physics 包，无状态的确定物理库（适合网络多人游戏）

​	2、Havok Physics 有状态但没有确定性的物理库，但比 Physics 更稳定和功能更强大



## Animation(WIP)

支持 DOTS



## Audio(WIP)

支持 DOTS



# DOTS 用在哪里（重要）

多线程加载、通讯、充分利用多核并行计算的游戏类型



1、具有大世界流式加载的游戏

2、具有复杂的大规模模拟的游戏

3、具有多种网络类型的多人联线游戏

4、具有需要客户端模拟预测的网络游戏（FPS游戏）



# 为什么需要 DOTS

程序性能的提升 远没有硬件提升的快 游戏主机硬件是固定的硬件 DOTS 提供了一套更简单的面向数据的代码编写模型

DOTS 编写出的程序充分利用现代CPU的多核并行设计



## 很多游戏的性能瓶颈不在渲染

很多游戏低分辨率用最新显卡也没有帧率提升。因为性能瓶颈在 CPU。

目前计算机硬件，CPU、GPU、内存 的发展不均衡，带宽限制

GPU 有独显的显存，但 CPU 和 内存 是添加高速缓存的内存层级结构去弥补 （ L1、L2、L3）

虽然有 高速缓存，但程序的设计不合理，还是会导致 Cache 使用的低效，会导致大型缓存收益效益递减



## 面向数据设计的本身是面向缓存友好的

可以极大增加缓存 Cache 的命中，提高效率



## 程序性能的提升 远没有硬件提升的快

摩尔定律的延续 依赖于 越来越好的工艺（2纳米）

提高CPU的速度主要依赖于提高主频、提高功率的时候降低发热，在占用空间越来越小的时候通过增加核数做并行处理提高处理能力

需要做指令并行，改进编译技术的支持才能发挥现代CPU设计的真正效率



## 其它并行编程库 - 依赖特定的硬件、针对科学计算

Intel TBB、OpenGL CUDA、OpenCL、MPI/OpenMPI 依赖特定的硬件、针对科学计算

集成到Unity中几乎不可用

DOTS 充分考虑游戏设计的需求，在 Unity 中兼容多平台多硬件的支持





# DOTS 前置基础 - 程序设计方法



## 指令化编程

​	汇编



## 函数化编程

​	小函数，模块化，数学科学计算领域



## 过程化编程

​	命令式，基于过程调用的概念，包含要执行的计划步骤，任何给定的过程都可以在程序执行过程中的任何时刻调用



## 面向对象设计 - OOD

​	OOD，面向对象设计。GameObject + OOP 会造成大量对象存在



## 面向数据设计：DOD

​	面向数据设计，CPU多核并行计算，多级缓存，大缓存的设计，对机器友好，对内存利用率高，可以用于大量游戏对象（万人同屏） - **DOD 本质 - 面向内存/缓存友好的设计**



# DOTS 前置基础 - CPU 



## 编译器的重要性

不同的编译器（如 GCC，Microsoft C++的编译器）在处理for 的嵌套循环遍历的时候 也会有不同的性能区别

GCC > Microsoft C++



## CPU 的速度 和 内存的速度 之间的差距弥补 - CPU 高速缓存 

CPU 高速缓存 可以在避免在内存问题上遇到卡顿的情况



## 为什么要使用 CPU 高速缓存

1、**指令并行性**

​	SIMD 指令消耗数据的书读比普通指令快了至少2-8倍



2、**编译器的技术改进太慢**

编译器的技术改进让程序的性能每隔18年才会翻一倍

不要指望编译器去提升运行速度



3、控制台不会遵循摩尔定律

固定硬件

第二代/第三代 游戏必须有所改进





## CPU 缓存的优势

启用多线程来并行化 遍历计算一个大型矩阵，每个线程单独计算

两种多线程的写法的效率上的差异：

写法一：

![多线程编程_1](images\多线程编程_1.png)



写法二：声明本地计数器（局部变量），修改的是局部变量，而不是在结果中增加数组元素

虽然使用了更多的堆栈空间去存储一个**局部变量**，但是在多线程环境下运行却远远的比写法一更快

**原因：CPU 缓存**

![多线程编程_2](images\多线程编程_2.png)



CPU 缓存：缓存少量异常快速的内存，保存的是最近访问的内存位置的结果



三种通用类型：

1、Data：D缓存，数据缓存，简称 D$

2、Instruction：I 缓存，指令缓存，简称 I$

​	在一开始的时候，因为 **指令缓存的命中率低** 的问题，路由数据包 的 速度：Linux > Window

​	微软将路由算法修改为本地缓存之后，Window 的路由数据包的速度比 Linux 快了 20%

3、Translation lookaside buffer：TLB，旁路转换缓存（页表缓存），将虚拟内存地址翻译成实际的物理内存地址。存放的是页表文件（虚拟地址到物理地址的转换表），当处理器要在主内存寻址的时候，不是直接在内存的物理地址查找的，而是通过一组虚拟地址转换到主内存的物理地址，CPU 寻址的时候会优先在 TLB 中寻址。处理器的性能和寻址的命中率有很大的关系。



## CPU 的三级缓存

如下CPU：

​	有 4个核心，

​	每个核心有2个线程，

​	有一个一级指令缓存和一个一级数据缓存，

​	有一个二级缓存，

​	最终进入三级缓存，

​	最后还有一个主内存，但是主内存是需要很长时间才能到达主内存

![CPU缓存结构](images\CPU缓存结构.png)



**CPU缓存特性缓存很小**

假设运行时程序为100MB(代码+数据)。

8%适合core-i79xx的L3缓存。每个运行进程(包括操作系统)共享L3缓存。

0.25%适合每个L2缓存。

0.03%适合每个L1缓存。



**缓存比主存储器快得多**

l对于Core i7-9xx:

L1延迟为4个周期。

L2延迟是11个周期。

L3时延为39个周期。

主内存延迟为107个周期：

​	比L1慢27倍 

​	虽然 Profiler 会显示 100% CPU利用率，但是实际上是 99% CPU空闲时间，因为大多数的程序分析器将 CPU正在等待一条指令或者从主内存传送数据看作为100%繁忙



**有效内存= CPU缓存内存**

从速度的角度来看，总内存=总缓存。

1、酷睿i7-9xx拥有8MB的快速内存。L1和L2缓存中的所有内容也在L3缓存中。

2、非缓存访问可能会减慢速度。

小=快

1、没有硬件级别的时间/空间权衡。

2、适合缓存的紧凑、本地化良好的代码是最快的。

3、适合缓存的紧凑数据结构是最快的。

4、只接触缓存数据的数据结构遍历是最快的。



## CPU 缓存行 - 缓存行组成缓存



**高速缓存线路（缓存行）**

缓存由行组成，每一行包含多个相邻的单词。

在酷睿i7上，缓存行有64字节。

​	1、Intel/AMD处理器常用的64字节行。

​	2、64字节= 16个32位值，8个64位值等。

​		例如，16个32位数组元素。



## CPU 缓存命中

**缓存行对主内存进行读/写**

1、读取不在缓存中的字节→从主内存读取完整的缓存行。

2、写字节→写完整的缓存行到主内存(最终)



**注意：哪怕读取和写入都是只需要一个字节，都会将整个缓存行进行读写操作，极大的浪费，缓存未命中**



**行矩阵遍历比列矩阵遍历更快的原因：直接沿着缓存行去运行，更少的缓存未命中**

如果不在内存，就需要等待107个周期来读取在主内存中数组的第一个元素，但是当做行矩阵遍历的时候会自动获取后续元素，因此必须等待第一个元素，但是其他的元素已经在内存中，这也就压缩了缓存行，并且能够立即计算出结果



## CPU 缓存行的预提取

硬件会推测性地预取缓存行:

正向遍历缓存行n→预取行n+1

反向遍历缓存行n→预取行n-1

**在任意一个方向上线性的穿过内存，是最适合缓存进行数据访问和指令访问的事情**



## CPU 缓存的一致性 -  解决数据竞争

两个不同的核心都在(虚拟)地址A缓存了同一个值。

不管是L1还是L2都没有区别。



假设：

在Core 0上运行的某些线程已经访问了某些内存位置，访问会从主内存引入，而 指令或者数据 已经位于二级缓存

在Core 1上运行了一个新的线程，并且也恰好访问了这个相同的数据元素

Core 0 对这个位置执行了写入操作，Core 1 在这个相同的位置执行的是读取操作，在硬件上同时进行

现在Core 1读取的值 是否就是 Core 0 写入的新值

错误的解决方案：

多线程编程中，当有两个或者多个线程访问相同内存位置时候，必须避免竞争，必须至少其中一个是正确的并且没有同步，为了解决这个问题，会使用互斥的解决方案，或者使用 原子指令 或者 原子变量



假设：

Core 0访问A位置，Core 1访问A+1位置。

虽然是独立的内存块;并发访问是安全的。

但是A和A+1可能映射到同一条缓存行上，而缓存行是主内存和缓存系统的交互的介质。

错误的解决方案：

在写入的时候会将整个缓存行标记为脏，在其他所有缓存中标记为脏，意味着不再有效

任何写入都会使同一个CPU上的所有副本和缓存标记为脏

如果是多处理器，四个电路板有四个核心的话，一共有16核心，那么在写入一个缓存行的时候，并且这个缓存行的副本在整个缓存系统中无效，并且电子也需要一定的时间才能从一个电路板到达下一个电路板，虽然是正确的，但是需要一定的时间。



错误的共享（解决数据竞争）的解决方案：

只有下面条件都为True的，问题才会出现：

1、独立的值/变量落在同一条缓存线上。

2、不同的内核同时访问该行。

3、频繁。

4、至少有一个是写入。



所有类型的数据都容易受到影响：

1、静态分配的(例如，全局变量、静态变量)。

2、堆分配。

3、自动并且线程局部变量（如果多个线程同时访问同一个内存，无法分发指针/引用）



**正确的解决数据竞争的解决方案**

**给每个线程提供自己的局部变量去自增计算结果，最后再赋值一次**

因为当任何线程执行加号操作的时候，会在缓存系统中的所有其他缓存中将整个缓存行标记为脏的状态

线程中的局部变量会创建在每个线程的自己的堆栈上，并且这个堆栈不会与此处另一个线程的堆栈位于同一个高速缓存行上，这也就是意味着每个单独的线程都会有自己的局部变量，并且这个局部变量在自己的缓存行上，最后再将局部变量写入最终结果，但是操作只会有一次。



如果代码没有很多调用很多循环，没有很多的分支会运行的更快

原因：因为正在读取指令的缓存行，硬件会预提取。如果有从上到下的没有分支的直线代码，就会非常适合从指令缓存中读取数据。



## CPU 缓存满意的设计 - 面向数据设计

从读取的每个单独的缓存行中获取最大的价值

一种以 CPU 缓存满意的方式，在内存中去布置数据结构

不会放置一个布尔值作为对象去标记是否在内存中存活（不会在对象内有布尔值），而是会有一个单独的数据结构体 Struct，由位组成去指示一个对象是否在内存中存活，读取64个字节的时候，可以拥有至少64个对象的在内存中的存活信息













































## CPU 架构 与 缓存层级结构



![CPU架构与缓存层级结构](images\CPU架构与缓存层级结构.png)



### CPU 中有 L1、L2、L3 三级缓存

L1级缓存：每个指令处理单元独享，又可以分为 L1D（缓存数据）、L1I（缓存指令）

L2级缓存：CPU核内多个指令处理单元共享

L3级缓存：CPU多个核所共享，负责与内存和显卡里的显存交换数据



### Cache line 缓存行

CPU 在执行程序指令时获取指令与数据，访问的单位（32或64字节）会根据系统和架构的不同有所差异，把基础大小单位称为 Cache line 缓存行

即使请求的是一个字节的大小，实际上会得到一个 Cache Line 的缓存行数据，在Cache缓存内可以将 N 个缓存行大小的缓存通过 DirectMap 直接映射到同一逻辑缓存行



### 逻辑缓存行

逻辑缓存行：可以对应多个物理行帮助最小化缓存行的抖动（挪动指针到每个物理缓存行的头）



### Cycle

CPU 指令的 Cycle：CPU 逻辑处理单元，通过 fetch 获得 L1I 指令缓存中的指令，再通过 Decode 解码，Execute 执行，在指令完成之后将数据回写到 LED 中完成一条程序指令



## Cache 的 3C 与 3R



### 3C

1、Compulsory misses：首次读取数据时候不可避免的 Miss

2、Capacity misses：缓存空间不足的时候，连续使用期间访问数据过多的话，无法保存所有活动的数据

3、Conflict misses：发生访问冲突的时候，由于数据映射到相同的逻辑缓存行，导致缓存的抖动



### 3R

1、Rearrage 重新排列（代码、数据）：更改布局以增加数据空间的局部性

2、Reduce 减少（大小、缓存行读取）：更小更智能的格式来压缩数据，如修改数据类型或使用位计算

3、Reuse 重用（Cache Lines）：增加数据的时间（和空间）的局部性，对齐，连续访问，减少发生缓存抖动的几率



# 面向数据设计需要思考的问题

需要更了解内存、缓存 的特性

需要更了解系统、硬件

需要更了解芯片指令与数据结构设计

![面向数据设计需要思考的问题](images\面向数据设计需要思考的问题.png)



# DOTS 面向数据设计原则

![DOTS面向数据设计原则](images\DOTS面向数据设计原则.png)



































































































# DOTS：面向数据技术栈

DOTS ：面向数据技术栈，具体 DOD 的解决方式

充分利用多核处理器，多线程处理 让游戏的运行速度更快更高效

由三部分构成：C# Job System、Burst 编译器、实体组件系统（ECS）

![](images\DOTS性能数据.png)



**CPU 缓存友好 + SIMD + 多线程 + struct去掉GC + LLVM burst 编辑器优化**



## 1. Burst Compiler：新编译器

以前：需要转换为中间代码，比较慢

Burst 编译器：不需要经过中间代码，直接变成汇编语言/机器码，效率更高

生成高度优化的本地代码



## 2. Job System：多线程



以前：单线程。一个CPU有很多的核，但是只有一个主线程在使用，其他的核都处于空闲的状态

Job System：多线程编程。当海量数据来临的时候，CPU 所有的核心都在一起工作，系统效率得到提高。Unity 内部 处理了 死锁 的问题。



## 3. ECS （Entity/Component/System）



**ECS：优化缓存行么，提高缓存命中率**

ECS 将所有相同的组件在内存中都排列在一起



性能强悍，展示海量游戏对象（百万同屏）



以前：基于对象的运作，如：每一个GameObject 都有自己的刚体、渲染组件组成，在内存中都是分散的，同一时间对大量游戏对象进行内存处理的话效率很低。

ECS：流水线式运作，在实例化实体的时候，都是在内存中紧密的排列，可以海量数据的处理





# HPC# 高性能C

IL2CPP 与 Net Core 的效率相当 但是依然比 C++ 慢2倍

Unity 使用 Burst 编译后，可以让 C# 代码运行效率比 C++更快



操作原生：

1、C# class 类型数据的内存分配在堆上，程序员无法主动释放，必须等到 .Net 垃圾回收才可以真正的清理

2、IL2CPP虽然可以将 IL 转成 C++ 代码，但是 垃圾回收 使用的是 Boehm（贝姆），所以效率不等同于 C++

3、HPC# 就是 NativeArray<T> 可代替数组 T[] 数据类型包括值类型（float、int、uint、short、bool ...），enums，structs 和 其他类型的指针

4、NativeArray、NativeList 系列 API可以在 C# 层分配 C++ 中的对象，可以主动释放不需要进行 C#  的垃圾回收

5、Job System 中使用的就是 NativeArray



# 手游性能问题



## CPU-bound（CPU受限）

CPU 执行的 21ms 中

1、CPU执行引擎代码

2、逻辑代码

3、准备提交渲染数据到GPU

4、GPU开始工作的同时 CPU进入下一帧

（重复以上工作）

假如：GPU 提前完成了上一帧的渲染，CPU迟迟没有准备好这一帧需要提交的数据，造成了 GPU等待（Wait）



出现 CPU 受限主要有以下原因：

1、逻辑代码过于耗时

2、Application.targetFrameRate 限帧



![](images\CPU-bound.png)



## GPU-bound（GPU受限）

CPU 卡住了，GPU 等待



GPU-bound：

GPU 上一帧的计算迟迟没有结束

CPU 即使准备好提交 GPU的数据 也得等着



Gfx.WaitForPresent in profiler



![](images\GPU-bound.png)





最完美的结果是 CPU 和 GPU 都不需要等待对方

缺点：帧率过高会导致机器发热

需要适当降帧