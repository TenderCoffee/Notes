# 事后统计法 - 统计监控得到的数据

正确，但是有 **<u>非常大局限性</u>**

1、测试结果非常依赖测试环境

​	硬件的不同

2、测试结果受数据规模的影响很大

​	待排序数据的有序度不一样，排序的执行时间就会有很大的差别

​	小规模的数据排序，插入排序可能比快速排序更快

​	大规模的数据排序，快速排序可能比插入排序更快



# 时间、空间复杂度分析 - 衡量算法代码执行效率

一个不用具体的测试数据来测试就可以粗略估计算法执行效率的方法

越高阶复杂度的算法，执行效率越低：

​	1、一个低阶的时间复杂度程序有极大的可能性会优于一个高阶的时间复杂度程序

​	2、不能直接断定就觉得O(logN)的算法一定优于O(n), 针对不同的宿主环境，不同的数据集，不同的数据量的大小，在实际应用上面可能真正的性能会不同



从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )

![](.\images\低阶到高阶.jpg)



# 1、大O复杂度表示法 - T(n) = O(f(n))

算法的执行效率 ≈ 算法代码执行时间 => 大O复杂度表示法 = 不运行代码就可以看到代码的执行时间



CPU 运行 的实际情况：对每一行 读数据-运算-写数据。每行代码执行的时间（指令周期）都不一样。

假设：如果 每行代码执行的时间都一样，**所有代码的执行时间 T(n) 与每行代码的执行次数 f(n) 成正比**

```
 int cal(int n) {			//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
   int sum = 0;				//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
   int i = 1;				//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
   for (; i <= n; ++i) {	//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
     sum = sum + i;			//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
   }						//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
   return sum;				//CPU 读数据-运算-写数据 CPU执行的个数、执行的时间（指令周期） 不定
 }
```



T(n) = O(f(n))

T(n) ：代码执行的时间；n ：数据规模的大小；f(n) ：每行代码执行的次数总和。

因为这是一个公式，所以用 f(n) 来表示。**公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比**

大O复杂度 不具体表示代码的真正执行时间，而是表示 **<u>代码执行时间随着数据规模增长的变化趋势（渐进时间复杂度  - 时间复杂度）</u>**



**数据规模（n）很大（无穷大）的时候，公式中的 低阶、常量、系数 不会左右增长趋势，可以直接忽略不计**。

**<u>只需要记录一个最大量级就可以</u>**

```
//T(n) = O(2n+2) => O(n)
int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }		
   return sum;
 }
 
 // T(n) = O(2n2+2n+3) => O(n²)
 int cal(int n) {
   int sum = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1;
     for (; j <= n; ++j) {
       sum = sum +  i * j;
     }
   }
 }
```



# 2、时间复杂度（渐进时间复杂度）分析的实用方法

1）单段代码看高频：比如循环。 

2）多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。 

3）嵌套代码求乘积：比如递归、多重循环等 

4）多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。



## 1、只关注循环执行次数最多的一段代码 - 最大阶

**只需要记录一个 最大阶 的量级**

在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以

```
 int cal(int n) {
   int sum = 0;				//常量级的执行时间，与 n 的大小无关，对复杂度没有影响直接忽略不计
   int i = 1;				//常量级的执行时间，与 n 的大小无关，对复杂度没有影响直接忽略不计
   for (; i <= n; ++i) {	//"被执行了 n次" 所以时间复杂度 = O(n)
     sum = sum + i;
   }
   return sum;
 }
```



## 2、加法法则：总复杂度 = 量级最大的代码的复杂度

分别分析每一部分的时间复杂度，然后把它们放到一块儿，再**取一个量级最大的作为整段代码的复杂度**

```

int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
   	//循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关
   	//循环次数为常量次数，可以忽略
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
```



第一段代码：

​		即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。

​		当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是**一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。**

第二段代码：时间复杂度 O(n)

第三段代码：时间复杂度 O(n²)



**总的时间复杂度就等于量级最大的那段代码的时间复杂度**

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).



## 3、乘法法则：“嵌套代码”的复杂度等于嵌套内外代码复杂度的乘机

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)×T2(n)=O(f(n))×O(g(n))=O(f(n)×g(n)).

假设 T1(n) = O(n)，T2(n) = O(n²)，则 T1(n) * T2(n) = O(n³)

把乘法法则看成是嵌套循环

```
//cal T1(n)
int cal(int n) {			
   int ret = 0; 
   int i = 1;
   for (; i < n; ++i) {	//产生嵌套 T(n) = T1(n) * T2(n) = O(n*n) = O(n2)
     ret = ret + f(i);		
   } 
 } 
 
 //f(i) 的时间复杂度 T2(n) = O(n)
 int f(int n) {
  int sum = 0;
  int i = 1;
  for (; i < n; ++i) {
    sum = sum + i;
  } 
  return sum;
 }
```



# 几种常见的时间复杂度

由数和字母的积组成的代数式叫做单项式，单独的一个数或一个字母也叫做单项式。

由若干个单项式相加组成的代数式叫做多项式。



复杂度量级 分类：

1、多项式量级：

O(1)、 O(logn)、 O(n)、 O(nlogn)、O(n²)、O(n³) ... k次方阶

2、非多项式量级**（非常低效的算法）**：只有两个：**<u>O(2ⁿ)  和  O(n!)</u>**  - NP问题：非多项式量级的算法问题

n! ：阶乘 - 3!就是1*2*3，n! 就是从1开始乘一直乘到n

n 越来越大，非多项式量级 执行时间几句增加，求解问题的执行时间无限增长

![](.\images\几种常见时间复杂度实例分析.webp)



## O(1)

常量级 时间复杂度 

并不是指只执行了一行代码

代码的执行时间不随 n 的增大而增长 = 时间复杂度 为 O(1)

```
//O(1)
 int i = 8;
 int j = 6;
 int sum = i + j;
```

一般只要算法中不存在 循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)



## O(logn)、O(nlogn) - 常见

对数阶 时间复杂度

```
//i的取值是一个等比数列
//每循环一次，i就乘于2， 执行x次，就有x个2相乘， 即2的x次方 当2的x次方大于n时，结束循环 所以，要求2的x次方=n
//x = 执行次数
 i=1;
 while (i <= n)  {
 	//这里是跳跃着执行
   i = i * 2;	// *3 = O(log₃n)
 }
```

2的x次方 =n =>  x = log₂n  （ x = 以2为底n的对数）



### O(logn)

对数阶时间复杂度，不论底数是几，都记为O(logn)，因为对数之间可以用换底公式相互转换

对数之间互相转换：log₃n = log₃2 * log₂n

即 O(log₃n) = O(C * log₂n)

因为 C=log₃2 是一个常量，大O表示法 忽略系数，即： O(Cf(n)) = O(f(n))

所以 O( log₂n) = O(log₃n)

对数阶时间复杂度表示法中，忽略对数的 底，统一表示为 O(logn)



### O(nlogn)

一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 

归并排序、快速排序



## O(m + n) 、 O(m * n)

代码的复杂度由两个数据的规模来决定

当存在多个数据规模，且无法判断哪个数据规模大的时候，无法直接套用 加法法则，需要保留多个数据规模。

但是乘法法则继续有效

```
//m+n 
//m 和 n 是表示两个数据规模
//T1(m) + T2(n) = O(f(m) + g(n))
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}

//m*n 第二个for循环嵌套在第一个for循环内
//T1(m)*T2(n) = O(f(m) * f(n))
int cal(int m, int n) {

  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;


    int sum_2 = 0;
    int j = 1;
    for (; j < n; ++j) {
      sum_2 = sum_2 + j;
    }

  }
  
  return sum_1 + sum_2;

}
```



# 3、空间复杂度（渐进空间复杂度）

算法的存储空间与数据规模之间的增长关系

```
//空间复杂度  O(n)
void print(int n) {
  int i = 0;						//申请空间存储变量 跟数据规模 n 没有关系 常量阶（忽略）
  int[] a = new int[n];				//申请了一个大小为 n 的 int 类型数组 剩下的代码都没有占用更多的空间
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```



**应用：存储一个二进制数，输入规模（空间复杂度）是O(logn) bit**

比如8用二进制表示就是3个bit。16用二进制表示就是4个bit。以此类推 n用二进制表示就是logn个bit

2^3= 8 

2^4= 16 

2^x= n

--> x = log2n  = log22 * log2n  

--> O(log2n) = O(C * log2n) =  O(log2n) =  O(logn)



（1）这里的输入规模指的是输入一个数，注意是一个，这个数（只讨论正整数）可以是0、1、2、...、n ，然后找出每个输入的数对应的空间大小，那么这里的映射关系就是我们要求的 “空间复杂度”。 

（2） 输入                                                          占用空间大小（bit）

 0、1                                                 						 →            1 

 2、3                                                  						→            2

 4、5、6、7                                       						→            3 

 8、9、10、11、12、13、14、15      					→            4

 ....                                                     							→            ... 

.....................................................................**n**   		 →            **m** 

输入小于等于1的数的时候，那么对应的占用的空间大小是1bit 

输入小于等于3的数的时候，那么对应的占用的空间大小是2bit 

输入小于等于7的数的时候，那么对应的占用的空间大小是3bit 

输入小于等于15的数的时候，那么对应的占用的空间大小是4bit 

我们输入小于等于n的数的时候，那么对应的占用的空间大小是多少呢？



（3）由上述映射关系很容易知道 **n = (2^m) -1**  那么 **m = log2 n+1**  ，

也就是当我输入一个任意小于等于n的数，那么其占用的空间大小即为 log2 n+1 

（4）综上所述，存储一个二进制数，输入规模(空间复杂度)是O(logn) bit



# 最好、最坏情况时间复杂度

只有同一块代码在不同的情况下，时间复杂度有量级的差距，才会使用这三种复杂度表示法来区分



```

// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
  	//不管查找的是哪个数值，数值在什么位置，都会遍历整个数组。 
  	//时间复杂度为 O(n)
    if (array[i] == x) pos = i;
  }
  return pos;
}


// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       //中途找到就可以提前结束循环
       //如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。
       //但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。
       //所以，不同的情况下，这段代码的时间复杂度是不一样的
       break;
    }
  }
  return pos;
}

```





## 最好情况时间复杂度

在最理想的情况下，执行这段代码的时间复杂度（极端情况下的代码复杂度，发生的概率其实并不大）



## 最坏情况时间复杂度

在最糟糕的情况下，执行这段代码的时间复杂度（极端情况下的代码复杂度，发生的概率其实并不大）



## 平均情况时间复杂度（平均时间复杂度）



### 加权平均值（期望值）

数组 遍历查找元素

要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中 + 不在数组中。

每种情况下，查找需要遍历的元素个数累加起来，然后再除以  n+1 ，就可以得到需要遍历的元素个数的平均值

![](.\images\平均情况时间复杂度_数组.webp)

1+..+n 为 n(n+1)/2 ，则再加个n，结果为 n(n+3)/2 ，再除以 n+1 ，结果为 n(n+3)/2(n+1)

注意：查找的 n+1 种情况 出现的概率不是一样的：

1、假设在数组中与不在数组中的概率都为 1/2

2、要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n

所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)

如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了

![](.\images\平均情况时间复杂度_加权平均值.webp)

最后得到 加权平均值： (3n+1)/4

**在算平均时间复杂度的时候,一定要把每种情况出现的概率(权重) 算进去**



### 平均时间复杂度 - 加权平均值 用大 O 表示法来表示

又称 加权平均时间复杂度、期望时间复杂度

平均时间复杂度的全称应该叫 加权平均时间复杂度 或者 期望时间复杂度

将 加权平均值  (3n+1)/4 用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)



# 均摊时间复杂度

```

 // array表示一个长度为n的数组
 // 代码中的array.length就等于n
 int[] array = new int[n];
 int count = 0;
 
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i < array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }

    array[count] = val;
    ++count;
 }
```



最理想的情况下，数组中有空闲空间，只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。

最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。



**代码分析：**

假设数组的长度是 n

1、根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。

2、还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。

而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度过程如下：

第一步：1/(n+1) + ... + 1/(n+1)  = n/(n+1)  

第二步：n/(n+1) 【第一步的结果】 + n/(n+1) = 2n/(n+1) 

第三步：根据复杂度计算，去掉系数就是 n/n 为 1 所以均摊时间复杂度为 O(1)

所以 平均时间复杂度是 O(1)



## 摊还分析（或者叫平摊分析）

针对大部分执行100%概率是低阶，很少概率是高阶时间复杂度的情况，我们不适合用平均时间复杂度去分析，这个时候用均摊时间复杂度分析较为合理

均摊复杂度，就是把量级高的操作所耗费的时间分担到量级低的操作上，看平摊后的量级是多少

**在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。**

**均摊时间复杂度是一种特殊的平均时间复杂度**



例子一：

```

// 全局变量，大小为10的数组array，长度len，下标i。
int array[] = new int[10]; 
int len = 10;
int i = 0;

// 往数组中添加一个元素
void add(int element) {
   if (i >= len) { // 数组空间不够了
     // 重新申请一个2倍大小的数组空间
     int new_array[] = new int[len*2];
     // 把原来array数组中的数据依次copy到new_array
     for (int j = 0; j < len; ++j) {
       new_array[j] = array[j];
     }
     // new_array复制给array，array现在大小就是2倍len了
     array = new_array;
     len = 2 * len;
   }
   // 将element放到下标为i的位置，下标i加一
   array[i] = element;
   ++i;
}
```

把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)



当i < len时, 即 i = 0,1,2,...,n-1的时候，for循环不走，所以这n次的时间复杂度都是O(1); 

当i >= len时, 即 i = n的时候，for循环进行数组的copy，所以只有这1次的时间复杂度是O(n); 

由此可知: 

该算法的最好情况时间复杂度为O(1); 

最坏情况时间复杂度为O(n); 

平均情况时间复杂度：

​	第一种计算方式: (1+1+...+1+n)/(n+1) = 2n/(n+1) 【注: 式子中1+1+...+1中有n个1】,所以平均复杂度为O(1); 

​	第二种计算方式(加权平均法，又称期望): 1×(1/n+1)+1×(1/n+1)+...+1×(1/n+1)+n×(1/(n+1))=1，所以加权平均时间复杂度为O(1); 

​	第三种计算方式(均摊时间复杂度): 前n个操作复杂度都是O(1)，第n+1次操作的复杂度是O(n)，所以把最后一次的复杂度分摊到前n次上，那么均摊下来每次操作的复杂度为O(1)



例子二：

进行添加操作的时候，ArrayList提供了两种添加方法：

 	1、add(int index,E element);//中间插入

 	2、add(E element); //末尾添加

末尾添加通常情况下时间复杂度为O(1)，但是考虑到最坏的情况可能会发生扩容，扩容则会进行拷贝数组的操作，时间复杂度就变为了O(n)。

但不会每次都是最坏情况，因此我们使用最坏的情况分析添加操作的时间复杂度是不合理的。

![](.\images\均摊复杂度.webp)

17次基本操作包含了9次添加操作 + 8次元素转移操作。平均每次 addLast 操作，进行2次基本操作（ 17/9 约等于2 ）

```
public void add(int index, E element) {
    rangeCheckForAdd(index);
    
    ensureCapacity(size + 1);
    
    for (int i = size; i > index; i--) {
        elements[i] = elements[i - 1];
    }
    elements[index] = element;
    size++;
}
```

假设capacity=n，n+1次addLast，触发resize，总共进行2n+1次基本操作

 平均每次addLast操作，进行2次基本操作（ (2n+1)/(n+1) 约等于 2 ）

 将1次resize的时间平摊给了n+1次addLast的时间，**于是得到了平均每次addLast操作进行2次基本操作的结论**

 这样均摊计算，时间复杂度是O(1)级别的，这和我们数组中有多少个元素是没有关系的

 在这个例子里，这样均摊计算，比计算最坏情况是有意义的，这是因为最坏的情况是不会每次都出现的。



一个相对比较耗时的操作，如果我们能保证他不会每次都被触发的话，那么这个相对比较耗时的操作它相应的时间是可以分摊到其它的操作中来的。

